# papers

### 1_AutoSpatial_Visual-Language_Reasoning_for_Social_Robot_Navigation_through_Efficient_Spatial_Reasoning_Learning
https://github.com/Yanko96/AutoSpatial 未公布
从CODA数据集中挑选72个具有挑战性的场景进行手动标注，重点关注高行人密度环境、复杂社交分组模式以及需要从个体到群体理解的场景。

https://zhuanlan.zhihu.com/p/1916578345426072770


### 2_CLOVER: Context-Aware Long-Term Object Viewpoint- and Environment- Invariant Representation Learning
https://github.com/ut-amrl/CLOVER
实现静态物体实例级重识别（re-identification），适用于移动服务机器人在真实世界（in-the-wild）长期运行。


### 3_EnvoDat: A Large-Scale Multisensory Dataset for Robotic Spatial Awareness and Semantic Reasoning in Heterogeneous Environments
面向环境鲁棒性机器人自主性的大规模多模态数据集

### 4_ReMEmbR: Building and Reasoning Over Long-Horizon Spatio-Temporal Memory for Robot Navigation
https://github.com/NVIDIA-AI-IOT/remembr
为机器人导航设计的长范围时空记忆系统，旨在解决机器人在长时间、复杂环境中对历史感知数据进行高效存储、检索和推理的挑战


### 5_Particle-Based Instance-Aware Semantic Occupancy Mapping in Dynamic Environments 
https://github.com/tud-amr/semantic_dsp_map
在存在移动物体（如行人、车辆）的真实环境中，构建一个既能区分静态/动态区域，又能识别每个物体实例（instance-aware），并以语义占用（semantic occupancy）形式表达的三维地图，而实现这一目标的关键技术是基于粒子（particle-based）的表示方法。


### 6_Exploring 3D Human Pose Estimation and Forecasting from the Robot’s Perspective: The HARPER Dataset
引入一个全新的、以移动机器人为中心的大规模数据集 HARPER


### 7_Is it safe to cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing
将多模态大语言模型（MLLM）——特别是 GPT-4V（GPT-4 Vision）——应用于行人（或机器人）过街安全决策的前沿探索。其核心目标不仅是判断“能否过街”，更强调提供可解释、细粒度的风险评估理由，以增强人机信任与系统可靠性。


### 8_Looking Inside Out: Anticipating Driver Intent From Videos
从车载摄像头或外部视角的视频流中，实时推断驾驶员的潜在意图（如变道、转弯或刹车），以增强人机协作能力。


### 9_LiRaFusion: Deep Adaptive LiDAR-Radar Fusion for 3D Object Detection
在复杂环境（如恶劣天气、低光照）下，通过深度自适应融合激光雷达（LiDAR）与毫米波雷达（Radar）数据，实现鲁棒、高精度的 3D 目标检测。

### 10_Wait, That Feels Familiar: Learning to Extrapolate Human Preferences
for Preference-Aligned Path Planning
旨在解决机器人在视觉导航中对新颖地形或光照变化的适应性问题




